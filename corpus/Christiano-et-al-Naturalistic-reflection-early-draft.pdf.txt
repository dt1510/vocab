Deﬁnability of “Truth” in Probabilistic Logic
(Early draft)
Paul Christiano∗

Eliezer Yudkowsky†
Mihaly Barasz§

Marcello Herreshoﬀ‡

April 2, 2013

1

Introduction

A central notion in metamathematics is the truth of a sentence. To express this notion within
a theory, we introduce a predicate True which acts on quoted sentences ϕ and returns their
truth value True ( ϕ ) (where ϕ is a representation of ϕ within the theory, for example
its G¨del number). We would like a truth predicate to satisfy a formal correctness property:
o
∀ϕ : True ( ϕ ) ⇐⇒ ϕ.

(1)

Unfortunately, it is impossible for any expressive language to contain its own truth predicate
True. For if it did, we could consider the liar’s sentence G deﬁned by the diagonalization
G ⇐⇒ True ( ¬G ) .
Combining this with property 1, we obtain:
G ⇐⇒ True ( ¬G ) ⇐⇒ ¬G,
a contradiction.
There are a few standard responses to this challenge.
The ﬁrst and most popular is to work with meta-languages. For any language L we may
form a new language by adding a predicate True, which acts only on sentences of L (i.e.,
sentences without the symbol True) and satisﬁes property 1. We can iterate this construction
to obtain an inﬁnite sequence of languages L1 , L2 , . . ., each of which contains the preceding
language’s truth predicate.
∗

UC Berkeley. Email: paulfchristiano@eecs.berkeley.edu
Machine Intelligence Research Institute
‡
Google
§
Google
†

1

A second approach is to accept that some sentences, such as the liar sentence G, are neither
true nor false (or are simultaneously true and false, depending on which bullet we feel like biting). That is, we work with a many-valued logic such as Kleene’s logic over {True, False, ⊥}.
Then we may continue to deﬁne True by the strong strong reﬂection property that the truth
values of ϕ and True ( ϕ ) are the same for every ϕ. We don’t run into trouble, because any
would-be paradoxical sentence can simply be valued as ⊥.
Although this construction successfully dodges the “undeﬁnability of truth” it is unsatisfying
in many respects. There is no way to test if a sentence ϕ is undeﬁned (any attempt to do so
will itself be undeﬁned), and there is no bound on the number of sentences which might be
undeﬁned. In fact, if we are speciﬁcally concerned with self-reference, then many sentences
of interest (and not just pathological counterexamples) may be undeﬁned.
In this paper we show that it is possible to perform a similar construction over probabilistic
logic. Though a language cannot contain its own truth predicate True, it can nevertheless
contain its own “subjective probability” function P. The assigned probabilities can be reﬂectively consistent in the sense of an appropriate analog of the reﬂection property 1. In
practice, most meaningful assertions must already be treated probabilistically, and very little
is lost by allowing some sentences to have probabilities intermediate between 0 and 1. (This
is in contrast with Kleene’s logic, in which the value ⊥ provides little useful information
where it appears.)

2
2.1

Preliminaries
Probabilistic Logic

Fix some language L, for example the language of ﬁrst order set theory. Fix a theory T over
L, for example ZFC. We are interested in doing “probabilistic” metamathematics within L,
and so in addition to assuming that it is powerful enough to perform a G¨del numbering, we
o
will assume that some terms in L correspond to the rational numbers and have their usual
properties under T . (But T will still have models in which there are non-standard rational
numbers, and this fact will be important later.)
We are interested in assignments of probabilities to the sentences of L. That is, we consider functions P which assign a real P (ϕ) to each sentence ϕ. In analogy with the logical
consistency of an assignment of truth values to sentences, we are particularly interested in
assignments P which are internally consistent in a certain sense.
We present two equivalent deﬁnitions of coherence for functions over a language L:
Deﬁnition 1 (Coherence). We say that P is coherent if there is a probability measure µ
over models of L such that P (ϕ) = µ ({M : M |= ϕ}).
Theorem 1 (Equivalent deﬁnition of coherence). P is coherent if and only if the following
axioms hold:

2

1. For each ϕ and ψ, P (ϕ) = P (ϕ ∧ ψ) + P (ϕ ∧ ¬ψ).
2. For each tautology ϕ, P (ϕ) = 1.
3. For each contradiction ϕ, P (ϕ) = 0.
Proof. It is clear that any coherent P satisﬁes these axioms.
To show that any P satisfying these axioms is coherent, we construct a distribution over
complete consistent theories T which “reproduces” P and then appeal to the completeness
theorem.
Fix some enumeration ϕ1 , ϕ2 , . . . of all of the sentences of L. Let T0 = ∅ and iteratively
deﬁne Ti+1 in terms of Ti as follows. If Ti is complete, we set Ti+1 = Ti . Otherwise, let ϕj
be the ﬁrst statement which is independent of Ti , and let Ti+1 = Ti ∪ ϕj with probability
P (ϕj | Ti ) 1 and Ti+1 = Ti ∪ ¬ϕj with probability P (¬ϕj | Ti ). Because ϕj was independent
of Ti , the resulting system remains consistent. Deﬁne T = ∪i Ti . Since each Ti is consistent,
T is consistent by compactness. For each i, ϕi or ¬ϕi will be included in some stage Tj (in
fact at stage j = i + 1 at the latest), so T is complete.
Axiom 1 implies
P (ϕ | Ti ) = P (ϕ | Ti ∧ ϕj ) P (ϕj | Ti ) + P (ϕ | Ti ∧ ¬ϕj ) P (¬ϕj | Ti ) ,
thus the sequence P (ϕ | Ti ) is a martingale. Axiom 2 implies that if Ti ϕ, P (ϕ | Ti ) = 1
and if Ti ¬ϕ, P (ϕ | Ti ) = 0. Thus, this sequence eventually stabilizes at 0 or 1, and T ϕ
iﬀ this sequence stabilizes at 1. The martingale property then implies that T
ϕ with
probability P (ϕ | T0 ). By axiom 3, P (T0 ) = 1, so P (ϕ | T0 ) = P (ϕ).
This process deﬁnes a measure µ over complete, consistent theories such that P (ϕ) =
µ ({T : T ϕ}). For each complete, consistent theory T , the completeness theorem guarantees the existence of a model M such that M |= ϕ if and only if T ϕ. Thus we obtain a
distribution µ over models such that P (ϕ) = µ ({M : M |= ϕ}), as desired.
We are particularly interested in probabilities P that assign probability 1 to T . It is easy to
check that such P correspond to distributions over models of T .

2.2

Going meta

So far we have talked about P as a function which assigns probabilities to sentences. If we
would like L to serve as its own meta-language, we should augment it to include P as a
real-valued function symbol. Call the agumented language L .
We will use the symbol P in two diﬀerent ways—both as our meta-level evaluation of truth
in L , and as a quoted symbol within L . However, whenever P appears as a symbol in L ,
1

P (ϕj | Ti ) =

P(ϕj ∧Ti )
P(Ti ) .

It is easy to verify by induction that P (Ti ) > 0.

3

its argument is always quoted. This ensures that references are unambiguous: “P (ϕ) = p”
is a statement at the meta level, i.e. “ϕ is true with probability p”, while “P ( ϕ ) = p” is
the same sentence expressed within L , which is in turn assigned a probability by P.

3
3.1

Reﬂection
Reﬂection principle

We would now like to introduce some analog of the formal correctness property 1, which we
will call a reﬂection principle.
This must be done with some care if we wish to avoid the problems with schema 1. For
example, we could introduce the analogous reﬂection principle:
∀ϕ ∈ L ∀a, b ∈ Q : (a < P (ϕ) < b) ⇐⇒ P (a < P ( ϕ ) < b) = 1

(2)

But this leads directly to a contradiction: if we deﬁne G ⇐⇒ P ( G ) < 1, then
P (G) < 1 ⇐⇒ P (P ( G ) < 1) = 1 ⇐⇒ P (G) = 1,
which contradicts P (G) ∈ [0, 1].
To overcome this challenge, we imagine P as having access to arbitrarily precise information
about P, without having access to the exact values of P. Let (a, b) be an open interval
containing P (ϕ). Then a suﬃciently accurate approximation to P (ϕ) would let us conclude
P (ϕ) ∈ (a, b), and so we have P (ϕ) ∈ (a, b) =⇒ P (P ( ϕ ) ∈ (a, b)) = 1. However, the
converse is not necessarily true. If P (ϕ) = a, then no possible approximation can distinguish
between the cases P (ϕ) < a, P (ϕ) = a, and P (ϕ) > a. So the reverse implication requires
closed rather than open intervals: for any closed interval [a, b] not containing P (ϕ), we could
infer P (ϕ) ∈ [a, b] from any suﬃciently accurate approximation to P (ϕ), and thus we should
have P (ϕ) ∈ [a, b] =⇒ P (P ( ϕ ) ∈ [a, b]) = 0.
This suggests the following criteria:
∀ϕ ∈ L ∀a, b ∈ Q : (a < P (ϕ) < b) =⇒ P (a < P ( ϕ ) < b) = 1

(3)

∀ϕ ∈ L ∀a, b ∈ Q : (a ≤ P (ϕ) ≤ b) ⇐= P (a ≤ P ( ϕ ) ≤ b) > 0

(4)

We say that P is reﬂectively consistent if it satisﬁes these properties. Our goal is to show
that starting from any consistent theory T we can obtain a reﬂectively consistent P which
assigns probability 1 to each sentence of T .
The intuition behind the description “reﬂective consistency” is that such a P would not
change upon further reﬂection. This is exactly analogous to the standard view of truth
as a ﬁxed point of a certain revision operation, and indeed we show that such P exist
by constructing an appropriate revision operation and appealing to Kakutani’s ﬁxed point
theorem.
4

In fact, property 3 and property 4 are equivalent. For suppose that property 3 holds, and
that P (ϕ) < a or P (ϕ) > b. Then either P (P ( ϕ ) < a) = 1 or P (P ( ϕ ) > b) = 1, and in
either case P (a ≤ P ( ϕ ) ≤ b) = 0. But this is precisely the contrapositive of propety 4. A
similar argument can be applied to show that property 4 implies property 3. In light of this
equivalence, we will focus only on property 3, and call this property the reﬂection principle.

3.2

Discussion of reﬂection principle

Given a statement such as G ⇐⇒ P ( G ) < p, a reﬂectively consistent distribution P will
assign P (G) = p. If P (G) > p, then P (P ( G ) > p) = 1, so P (G) = 0, and if P (G) < p,
then P (P ( G ) < p) = 1, so P (G) = 1. But if P (G) = p, then P is “uncertain” about
whether P (G) is slightly more or slightly less than p. No matter how precisely it estimates
P (G), it remains uncertain.
If we look at the models of L corresponding to reﬂectively consistent distributions P, they
have P ( G ) ∈ (p − , p + ), where is a non-standard inﬁnitesimal which lies strictly
between 0 and every standard rational number. That is, P is “mistaken” about itself, but
its error is given by the inﬁnitesimal . (These are the same inﬁnitesimals which are used to
formalize diﬀerentiation in nonstandard analysis.)
Although this paper focuses on Tarski’s results on the undeﬁnability of truth, similar paradoxes are at the core of G¨del’s incompleteness theorem and the inconsistency of unrestricted
o
comprehension in set theory. A similar approach to the one taken in this paper is adequate
to resolve some of these challenges, and e.g. to construct a set theory which satisﬁes a
probabilistic version of the unrestricted comprehension axiom.
We will prove that there are many reﬂectively consistent distributions, but our proof will be
non-constructive. In fact any coherent P is necessarily uncomputable, whether or not it is
reﬂectively consistent. But the mere existence of a reﬂectively consistent distribution implies
that the property 3 will not lead to any contradictions if treated as a rule of inference which
connects a reasoner’s beliefs about P (ϕ) to its beliefs about ϕ itself. So even though we
cannot construct any reﬂectively consistent P, their existence may still have pragmatic implications for reasoning (in the same way that introducing the predicate True might usefully
increase the expressive power of a language, even though the extension of that predicate is
necessarily uncomputable).

3.3

Proof of consistency of reﬂection principle

The most important result of this paper is the following theorem:
Theorem 2 (Consistency of reﬂection principle). Let L be any language and T any consistent
theory over L, and suppose that the theory of rational numbers with addition can be embedded
in T in the natural sense. Let L be the extension of L by the symbol P as above. Then there is
a probabilistic valuation P over L which is coherent, assigns probability 1 to T , and satisﬁes

5

the reﬂection principle:
∀ϕ ∈ L ∀a, b ∈ Q : (a < P (ϕ) < b) =⇒ P (a < P ( ϕ ) < b) = 1.
Proof. Let A be the set of coherent probability distributions over L which assign probability
1 to T . We consider A as a subset of [0, 1]L with the product topology. Clearly A is convex.
By using the alternative characterization of coherence, we can see that A is a closed subset of
[0, 1]L . Thus by Tychonoﬀ’s theorem, we conclude that A is compact. Moreover, because T
is consistent, A is non-empty—for example, let M be any model of T , in which each P ( ϕ )
is assigned some arbitrary value, and let P (ϕ) = 1 if M |= ϕ and 0 otherwise.
Given any P ∈ A, let RP be the schema of axioms of the form a < P ( ϕ ) < b where
a, b are the endpoints of a rational interval containing P (ϕ). We will write P (RP ) = 1
as shorthand for ∀ψ ∈ RP : P (ψ) = 1 (this notation is justiﬁed, since RP is countable).
Deﬁne f : A → P (A) by f (P ) = {P ∈ A : P (RP ) = 1}. If P ∈ f (P) then P is reﬂectively
consistent and we are done.
Each f (P) is convex and non-empty by the same argument that A itself is. We will show
that f has a closed graph; we can then apply the Kakutani ﬁxed point theorem to ﬁnd some
P ∈ f (P), as desired. (The Kakutani ﬁxed-point theorem applies to [0, 1]L because it is a
convex subset of a Hausdorﬀ and locally convex topological vector space.)
Let {Pi }i , {Pi }i be sequences in A such that Pi ∈ f (Pi ) for each i. We need to show that
if Pi → P and Pi → P (in the product topology) then P ∈ f (P ). Since A is closed,
we have P ∈ A. So it remains to show that P (RP ) = 1. Pick any a, b, ϕ such that a <
P (ϕ) < b. Since Pi converges to P , for all suﬃciently large i we have a < Pi < b, and thus
Pi (a < P ( ϕ ) < b) = 1. Since Pi converges to P, we have P (a < P ( ϕ ) < b) = 1. Thus
P (RP ) = 1 We conclude that f has a closed graph, so we can apply the Kakutani ﬁxed
point theorem to ﬁnd P ∈ f (P), as desired.

3.4

Going meta

An important point is that the reﬂection principle is a statement which is true about P,
not an axiom to which P assigns probability 1. That is, each statement of the form
(a < P (ϕ) < b) =⇒ P (a < P ( ϕ ) < b) = 1 is true. This is what we need in order for
the reﬂection principle to meaningfully constrain the values of P—we don’t want P to assert
that P is reﬂectively consistent, we want it to actually be reﬂectively consistent.
That said, we might also want P to assign probability 1 to its own reﬂective consistency. To
this end, note that any reﬂectively consistent P also satisﬁes
∀ > 0 ∀ϕ ∈ L ∀a, b ∈ Q : P ((a ≤ P ( ϕ ) ≤ b) =⇒ P ( a < P ( ϕ ) < b ) > 1 − ) = 1.
(5)
Indeed, for each a, b, , ϕ, if the antecedent of 5 is false we assign it probability 0, and if
the consequent is true we assign it probability 1. Once again, we can’t get exactly what
6

we want, but we can get it up to some arbitrarily small error. The most unsatisfying thing
about property 5 is not this inﬁnitesimal error: it is that P appears inside the quantiﬁers.
We would really like P to assert its own reﬂective consistency in general, not just in each
speciﬁc case. That is, we would like:
P (∀ϕ ∈ L ∀a, b ∈ Q : (a < P ( ϕ ) < b) =⇒ P ( a < P ( ϕ ) < b ) = 1) = 1,
but we do not prove that P has this property. Indeed, if P assigns probability 1 to property 3,
then we have observed that P must also assign probability 1 to property 4. But then we
have
P (a ≤ P ( ϕ ) ≤ b) > 0 =⇒ P (P ( a ≤ P ( ϕ ) ≤ b ) > 0) = 1
=⇒ P (a ≤ P ( ϕ ) ≤ b) = 1
which leads to a contradiction. In fact, a similar argument shows that P must assign probability 0 both to property 3 and property 4.
In order to devise a reﬂection principle which is simultaneously satisﬁed by P and assigned
probability 1 by P, we need to weaken property 3. One alternative reﬂection principle is
an approximate verison of the intuitively appealing identity P (ϕ | P ( ϕ ) = p) = p, which
formalizes the notion of “self-trust” rather than “self-knowledge.” For example, we could
consider the relaxation
∀ϕ ∈ L ∀a, b ∈ Q : P (ϕ ∧ (a < P ( ϕ ) < b)) ≤ bP (a ≤ P ( ϕ ) ≤ b)
∀ϕ ∈ L ∀a, b ∈ Q : P (ϕ ∧ (a ≤ P ( ϕ ) ≤ b)) ≥ aP (a < P ( ϕ ) < b)
This is strictly weaker than our proposed reﬂection principle, so our result implies that there
exist coherent P satisfying this principle. Moreover, no obvious analog of the Liar’s paradox
prevents this property from being both satisﬁed by P and assigned probability 1 by P. (This
property may be viewed as an approximate, asynchronous version of van Frassen’s Reﬂection
Principle. The exact version of van Frassen’s principle is easily seen to be subject to the
liar’s paradox.)
It remains open whether it is possible to devise a principle which captures the important
aspects of reﬂective consistency, and which can be simultaneously true of a distribution P
and assigned probability 1 by P. However, our work shows that the obstructions presented
by the liar’s paradox can be overcome by tolerating an inﬁnitesimal error, and that Tarski’s
result on the undeﬁnability of truth is in some sense an artifact of the inﬁnite precision
demanded by reasoning about complete certainty.

7

