AGI Safety and Whole Brain Emulation Should humanity accelerate WBE development?
Accelerators Other factors, however, may accelerate progress toward AI: More hardware.
So Neville slowed down, pulled back, angled up out of the forest and began to accelerate back toward where the Chaos Legion still marched.
Participants in this discussion began in broad disagreement about whether it would be wise to accelerate WBE research for the purposes of future AGI safety.
He can go up against gravitation in a balloon, and why should he not hope that ultimately he may be able to stop or accelerate his drift along the Time-Dimension, or even turn about and travel the other way?'
Thus, despite many shortcomings in the design of this expert elicitation, the group’s current collective best guess, given the considerations evaluated so far, is that humanity should not accelerate WBE-related tech.
(However, this raises ethical concerns and may be morally equivalent to killing the researcher.) If it is correct that WBE would improve humanity’s chances of successfully navigating the first creation of AGI, we might be able to accelerate WBE development—e.g.
I would suggest that we think, not in terms of developing or not-developing technologies, but in terms of our pragmatically available latitude to accelerate or slow down technologies; and ask, within the realistic bounds of this latitude, which technologies we might prefer to see developed before or after one another.
Methods like neural networks (imported from neuroscience) and reinforcement learning (inspired by behaviorist psychology) have already resulted in significant AI progress, and experts expect this insight-transfer from neuroscience to AI to continue and perhaps accelerate (Van der Velde 2010; Schierwagen 2011; Floreano and Mattiussi 2008; de Garis et al.
We will not assume the continuation of Moore’s law, nor that hardware trajectories determine software progress, nor that faster computer speeds necessarily imply faster “thought” (Proudfoot and Copeland 2012), nor that technological trends will be exponential (Kurzweil 2005) rather than “Scurved” or otherwise (Modis 2012), nor indeed that AI progress will accelerate rather 1.
But 90% confidence that AI will not arrive before the end of the century also seems wrong, given that: (a) many diﬃcult AI breakthroughs have now been made (including the Gödel machine and AIXI), (b) several factors, such as automated science and first-mover incentives, may well accelerate progress toward AI, and (c) whole brain emulation seems to be possible and have a more predictable development than de novo AI.
The world’s scientific output (in publications) grew by one third from 2002 to 2007 alone, much of this driven by the rapid growth of scientific output in developing nations like China and India (Royal Society 2011).13 Moreover, new tools can accelerate particular fields, just as fMRI accelerated neuroscience in the 1990s, and the eﬀectiveness of scientists themselves can potentially be increased with cognitive enhancement pharmaceuticals (Bostrom and Sandberg 2009), and brain-computer interfaces that allow direct neural access to large databases (Groß 2009).
Because superhuman AI and other powerful technologies may pose some risk of human extinction (“existential risk”), Bostrom (2002) recommends a program of diﬀerential technological development in which we would attempt “to retard the implementation of dangerous technologies and accelerate implementation of beneficial technologies, especially those that ameliorate the hazards posed by other technologies.” But good outcomes from intelligence explosion appear to depend not only on diﬀerential technological development but also, for example, on solving certain kinds of problems in decision theory and value theory before the first creation of AI (Muehlhauser 2011).